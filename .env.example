# Database Configuration
# Choose: 'dynamodb' or 'postgres'
DATABASE_TYPE=dynamodb

# DynamoDB Configuration (via LocalStack)
DYNAMODB_ENDPOINT=http://localhost:4566
DYNAMODB_TABLE_NAME=feedback
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test

# PostgreSQL Configuration (if using Postgres instead of DynamoDB)
# Uncomment if using PostgreSQL:
# DATABASE_URL=postgresql://postgres:postgres@localhost:5432/feedback

# Ollama Configuration (FREE local LLM - no API keys needed!)
# Ollama runs in Docker on port 11434
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Alternative models you can try (after pulling them):
# OLLAMA_MODEL=llama3.2       # Recommended - Good balance for sentiment analysis (~2GB, 15-30 sec)
# OLLAMA_MODEL=llama3.2:1b    # Faster but less accurate (~1.3GB, 5-15 sec)
# OLLAMA_MODEL=llama3.1       # Larger/better quality (~4.7GB, slower)
# OLLAMA_MODEL=mistral        # Alternative model (~4.1GB)

# API Server Configuration
API_PORT=3001
NODE_ENV=development

# Frontend Configuration
VITE_API_URL=http://localhost:3001
